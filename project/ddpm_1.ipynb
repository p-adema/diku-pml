{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "dD0C2vndcuz6",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.079281Z",
     "start_time": "2025-01-09T10:51:45.496858Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Callable, Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import ddpm_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0lPcVfRWZRhQ",
    "outputId": "51795aca-2140-4c9f-940d-29aaebd99b66",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.085749Z",
     "start_time": "2025-01-09T10:51:47.082409Z"
    }
   },
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    import os\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
    "except ImportError:\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "assert Path(\"ddpm_models\").exists(), \"Couldn't find model folder\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "By7MSuvVcuz_",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.208327Z",
     "start_time": "2025-01-09T10:51:47.203886Z"
    }
   },
   "source": [
    "def train(\n",
    "    train_model: nn.Module,\n",
    "    train_optimizer: torch.optim.Optimizer,\n",
    "    train_scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "    train_dataloader: torch.utils.data.DataLoader[tuple[torch.Tensor, Any]],\n",
    "    train_epochs: int,\n",
    "    train_device: torch.device,\n",
    "    ema: bool = True,\n",
    "    per_epoch_callback: Callable = None,\n",
    "    double_bar: bool = False,\n",
    "    extra_desc: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Training loop\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_model: nn.Module\n",
    "        Pytorch model\n",
    "    train_optimizer: optim.Optimizer\n",
    "        Pytorch optimizer to be used for training\n",
    "    train_scheduler: optim.LRScheduler\n",
    "        Pytorch learning rate scheduler\n",
    "    train_dataloader: utils.DataLoader\n",
    "        Pytorch dataloader\n",
    "    train_epochs: int\n",
    "        Number of epochs to train\n",
    "    train_device: torch.device\n",
    "        Pytorch device specification\n",
    "    ema: Boolean\n",
    "        Whether to activate Exponential Model Averaging\n",
    "    per_epoch_callback: function\n",
    "        Called at the end of every epoch\n",
    "    double_bar: bool\n",
    "        Whether to add a progress bar within an epoch\n",
    "    extra_desc: str\n",
    "        Extra progress bar description\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup progress bar\n",
    "\n",
    "    if ema:\n",
    "        ema_global_step_counter = 0\n",
    "        ema_steps = 10\n",
    "        ema_adjust = train_dataloader.batch_size * ema_steps / train_epochs\n",
    "        ema_decay = 1.0 - 0.995\n",
    "        ema_alpha = min(1.0, (1.0 - ema_decay) * ema_adjust)\n",
    "        ema_model = ddpm_model.ExponentialMovingAverage(\n",
    "            train_model, avg_device=train_device, decay=1.0 - ema_alpha\n",
    "        )\n",
    "\n",
    "    full_bar = trange(\n",
    "        train_epochs,\n",
    "        desc=\"Training\" if not extra_desc else f\"Training ({extra_desc})\",\n",
    "        smoothing=0.05,\n",
    "        unit=\"epoch\",\n",
    "        position=1,\n",
    "    )\n",
    "    for epoch in full_bar:\n",
    "        # Switch to train mode\n",
    "        train_model.train()\n",
    "\n",
    "        epoch_bar = tqdm(\n",
    "            train_dataloader,\n",
    "            leave=False,\n",
    "            position=2,\n",
    "            desc=f\"Epoch {epoch}\",\n",
    "            disable=not double_bar,\n",
    "        )\n",
    "        for x, _label in epoch_bar:\n",
    "            x = x.to(train_device)\n",
    "            train_optimizer.zero_grad()\n",
    "            loss = train_model.loss(x)\n",
    "            loss.backward()\n",
    "            train_optimizer.step()\n",
    "            train_scheduler.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=f\"⠀{loss.item():12.4f}\",\n",
    "                lr=f\"{train_scheduler.get_last_lr()[0]:.2E}\",\n",
    "                refresh=False,\n",
    "            )\n",
    "\n",
    "            if ema:\n",
    "                ema_global_step_counter += 1\n",
    "                if ema_global_step_counter % ema_steps == 0:\n",
    "                    ema_model.update_parameters(train_model)\n",
    "\n",
    "        if per_epoch_callback:\n",
    "            per_epoch_callback(ema_model.module if ema else train_model)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gqPZ6PkScuz_",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.214640Z",
     "start_time": "2025-01-09T10:51:47.212414Z"
    }
   },
   "source": [
    "# Parameters\n",
    "T = 1000\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 256"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tBntJ5JFcuz_",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.257889Z",
     "start_time": "2025-01-09T10:51:47.220261Z"
    }
   },
   "source": [
    "# Rather than treating MNIST images as discrete objects, as done in Ho et al 2020,\n",
    "# we here treat them as continuous input data, by dequantizing the pixel values (adding noise to the input data)\n",
    "# Also note that we map the 0..255 pixel values to [-1, 1], and that we process the 28x28 pixel values as a flattened 784 tensor.\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(\n",
    "            lambda x: x + torch.rand(x.shape) / 255\n",
    "        ),  # Dequantize pixel values\n",
    "        transforms.Lambda(lambda x: (x - 0.5) * 2.0),  # Map from [0,1] -> [-1, -1]\n",
    "        transforms.Lambda(lambda x: x.flatten()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Download and transform train dataset\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"./mnist_data\", download=True, train=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYJ6BwrGcuz_",
    "outputId": "c5d81afe-e1b8-4fac-8762-efaa7d0da01c",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.278361Z",
     "start_time": "2025-01-09T10:51:47.263312Z"
    }
   },
   "source": [
    "# Select device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "elif torch.mps.is_available():\n",
    "    device = \"mps:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Running on {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on mps:0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KLr9MxVncu0A",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.293094Z",
     "start_time": "2025-01-09T10:51:47.289207Z"
    }
   },
   "source": [
    "def reporter(train_model: nn.Module):\n",
    "    \"\"\"Callback function used for plotting images during training\"\"\"\n",
    "\n",
    "    # Switch to eval mode\n",
    "    train_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        nsamples = 10\n",
    "        samples = train_model.sample((nsamples, 28 * 28)).cpu()\n",
    "\n",
    "        # Map pixel values back from [-1,1] to [0,1]\n",
    "        samples = (samples + 1) / 2\n",
    "        samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "        # Plot in grid\n",
    "        grid = utils.make_grid(samples.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "        plt.gca().set_axis_off()\n",
    "        plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcoxR2ajYkqe",
    "outputId": "cfa5ef9e-8164-48b1-8daa-b66b260788c2",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.302752Z",
     "start_time": "2025-01-09T10:51:47.298875Z"
    }
   },
   "source": [
    "# Base models, three different ways to predict the mean\n",
    "for tgt in (\"e\", \"u\", \"x0\"):\n",
    "    if Path(f\"ddpm_models/base_{tgt}.pt\").exists():\n",
    "        print(f\"Skipping target {tgt}, already exists\")\n",
    "        continue\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Construct Unet\n",
    "    # The original ScoreNet expects a function with std for all the\n",
    "    # different noise levels, such that the output can be rescaled.\n",
    "    # Since we are predicting the noise (rather than the score), we\n",
    "    # ignore this rescaling and just set std=1 for all t.\n",
    "    mnist_unet = ddpm_model.ScoreNet(None)\n",
    "\n",
    "    # Construct model\n",
    "    model = ddpm_model.DDPM(mnist_unet, max_t=T, predict_mean_by=tgt).to(device)\n",
    "    model.compile(fullgraph=True)\n",
    "\n",
    "    # Construct optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Setup simple scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9999)\n",
    "\n",
    "    # Call training loop\n",
    "    train(\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        dataloader_train,\n",
    "        train_epochs=epochs,\n",
    "        train_device=device,\n",
    "        ema=True,\n",
    "        per_epoch_callback=reporter,\n",
    "        extra_desc=f\"target={tgt}\",\n",
    "    )\n",
    "\n",
    "    torch.save(model, f\"ddpm_models/base_{tgt}.pt\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping target e, already exists\n",
      "Skipping target u, already exists\n",
      "Skipping target x0, already exists\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9c6e695c231445f79a9ca6a2e947077c",
      "45a6880274a441549307bb640ac3471b",
      "fd36141ee1674ef49ad1cd0f5c3700ad",
      "95d6ec38cbf94f9793011e180f1efa7f",
      "eb2982342ec44ccfbc49b836218f2cf2",
      "32d5d0c113b64b648fe736665d85fa27",
      "2bb91dbf551f4fda80bd0c58df06ae14",
      "f9fee4f7e0b543d38820385315415c09",
      "125e1ddec1fa49a18bd11bd9edc05f57",
      "ce69bade81de4d298cf2222d4b089898",
      "b8ff165799974fedb249846d0b56a5a8"
     ]
    },
    "id": "QjNqE_6Pcu0A",
    "outputId": "de8a4971-1524-4674-d559-4fd12da20f48",
    "ExecuteTime": {
     "end_time": "2025-01-09T10:51:47.314135Z",
     "start_time": "2025-01-09T10:51:47.310339Z"
    }
   },
   "source": [
    "# Noise predictor model, three different ways to reduce the variance\n",
    "for mthd in (\"low-discrepency\", \"importance-sampling\", \"importance-batch\"):\n",
    "    if Path(f\"ddpm_models/variance_{mthd}.pt\").exists():\n",
    "        print(f\"Skipping method {mthd}, already exists\")\n",
    "        continue\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    mnist_unet = ddpm_model.ScoreNet(None)\n",
    "    model = ddpm_model.DDPM(mnist_unet, max_t=T, reduce_variance_by=mthd).to(device)\n",
    "    model.compile(fullgraph=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9999)\n",
    "\n",
    "    train(\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        dataloader_train,\n",
    "        train_epochs=epochs,\n",
    "        train_device=device,\n",
    "        ema=True,\n",
    "        per_epoch_callback=reporter,\n",
    "        extra_desc=f\"method={mthd}\",\n",
    "    )\n",
    "\n",
    "    torch.save(model, f\"ddpm_models/variance_{mthd}.pt\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping method low-discrepency, already exists\n",
      "Skipping method importance-sampling, already exists\n",
      "Skipping method importance-batch, already exists\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "125e1ddec1fa49a18bd11bd9edc05f57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2bb91dbf551f4fda80bd0c58df06ae14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32d5d0c113b64b648fe736665d85fa27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45a6880274a441549307bb640ac3471b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32d5d0c113b64b648fe736665d85fa27",
      "placeholder": "​",
      "style": "IPY_MODEL_2bb91dbf551f4fda80bd0c58df06ae14",
      "value": "Training (method=importance-sampling): 100%"
     }
    },
    "95d6ec38cbf94f9793011e180f1efa7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce69bade81de4d298cf2222d4b089898",
      "placeholder": "​",
      "style": "IPY_MODEL_b8ff165799974fedb249846d0b56a5a8",
      "value": " 100/100 [34:04&lt;00:00, 20.37s/epoch]"
     }
    },
    "9c6e695c231445f79a9ca6a2e947077c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45a6880274a441549307bb640ac3471b",
       "IPY_MODEL_fd36141ee1674ef49ad1cd0f5c3700ad",
       "IPY_MODEL_95d6ec38cbf94f9793011e180f1efa7f"
      ],
      "layout": "IPY_MODEL_eb2982342ec44ccfbc49b836218f2cf2"
     }
    },
    "b8ff165799974fedb249846d0b56a5a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce69bade81de4d298cf2222d4b089898": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb2982342ec44ccfbc49b836218f2cf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9fee4f7e0b543d38820385315415c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd36141ee1674ef49ad1cd0f5c3700ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9fee4f7e0b543d38820385315415c09",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_125e1ddec1fa49a18bd11bd9edc05f57",
      "value": 100
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
